{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd6decdcb165d6b",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f229cb3bfd93b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:38:32.142431Z",
     "start_time": "2025-02-13T14:38:32.127247Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bash: pip install --upgrade python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:38:38.617239Z",
     "start_time": "2025-02-13T14:38:34.082545Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import openpyxl\n",
    "import re\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c80197e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now load all your files to the docs folder...\n"
     ]
    }
   ],
   "source": [
    "# Create 'docs' directory if it doesn't exist\n",
    "os.makedirs('docs', exist_ok=True)\n",
    "\n",
    "print(\"Now load all your files to the docs folder...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "874150981eceba2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:38:40.771011Z",
     "start_time": "2025-02-13T14:38:40.724539Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_sentences(file_path):\n",
    "    \"\"\"Extract sentences with proper resource cleanup\"\"\"\n",
    "    content_blocks = []\n",
    "    \n",
    "    try:\n",
    "        if file_path.lower().endswith('.xlsx'):\n",
    "            # Use pandas ExcelFile for better resource management\n",
    "            with pd.ExcelFile(file_path, engine='openpyxl') as xls:\n",
    "                for sheet_name in xls.sheet_names:\n",
    "                    df = xls.parse(sheet_name)\n",
    "                    for row_idx, row in df.iterrows():\n",
    "                        for col_idx, value in enumerate(row):\n",
    "                            cell_text = str(value)\n",
    "                            sentences = re.split(r'(?<=[.!?])\\s+', cell_text)\n",
    "                            for sentence in sentences:\n",
    "                                if sentence := sentence.strip():\n",
    "                                    content_blocks.append({\n",
    "                                        'source_type': 'worksheet',\n",
    "                                        'source_name': sheet_name,\n",
    "                                        'content': sentence,\n",
    "                                        'location': f\"Row {row_idx+1}, Col {df.columns[col_idx]}\"\n",
    "                                    })\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            # PDF handling with guaranteed closure\n",
    "            with open(file_path, 'rb') as f:\n",
    "                pdf = PdfReader(f)\n",
    "                for page_num, page in enumerate(pdf.pages, 1):\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        sentences = re.split(r'(?<=[.!?])\\s+', page_text)\n",
    "                        for sentence in sentences:\n",
    "                            if sentence := sentence.strip():\n",
    "                                content_blocks.append({\n",
    "                                    'source_type': 'page',\n",
    "                                    'source_name': f\"Page {page_num}\",\n",
    "                                    'content': sentence,\n",
    "                                    'location': None\n",
    "                                })\n",
    "        elif file_path.lower().endswith('.docx'):\n",
    "            # Word document handling\n",
    "            doc = Document(file_path)\n",
    "            for para_num, paragraph in enumerate(doc.paragraphs, 1):\n",
    "                paragraph_text = paragraph.text\n",
    "                if paragraph_text:\n",
    "                    sentences = re.split(r'(?<=[.!?])\\s+', paragraph_text)\n",
    "                    for sentence in sentences:\n",
    "                        if sentence := sentence.strip():\n",
    "                            content_blocks.append({\n",
    "                                'source_type': 'paragraph',\n",
    "                                'source_name': f\"Paragraph {para_num}\",\n",
    "                                'content': sentence,\n",
    "                                'location': None\n",
    "                            })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    return content_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de61aa06d49198f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:38:48.174988Z",
     "start_time": "2025-02-13T14:38:48.143708Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_keyword_matches(content_blocks, keywords):\n",
    "    \"\"\"Find exact keyword-containing sentences\"\"\"\n",
    "    matches = []\n",
    "    \n",
    "    for block in content_blocks:\n",
    "        lower_content = block['content'].lower()\n",
    "        found_keywords = [kw for kw in keywords if kw.lower() in lower_content]\n",
    "        \n",
    "        if found_keywords:\n",
    "            for keyword in found_keywords:\n",
    "                matches.append({\n",
    "                    'File Path': block.get('file_path', ''),\n",
    "                    'Source Type': block['source_type'],\n",
    "                    'Source Name': block['source_name'],\n",
    "                    'Location': block['location'],\n",
    "                    'Keyword': keyword,\n",
    "                    'Exact Sentence': block['content']\n",
    "                })\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf96135883e6e175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:38:50.588973Z",
     "start_time": "2025-02-13T14:38:50.557770Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_report(folder_path, keywords):\n",
    "    \"\"\"Generate report with guaranteed file closure\"\"\"\n",
    "    report = []\n",
    "    \n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.xlsx', '.pdf')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                content_blocks = extract_sentences(file_path)\n",
    "                for block in content_blocks:\n",
    "                    block['file_path'] = file_path\n",
    "                matches = find_keyword_matches(content_blocks, keywords)\n",
    "                report.extend(matches)\n",
    "    \n",
    "    return pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b052e7499a832c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:38:55.493953Z",
     "start_time": "2025-02-13T14:38:52.822399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "folder_path = 'docs' # Update this path\n",
    "keywords = ['Gender', 'Transgender','transmen', 'transwomen' , 'LGBTQ', 'LGBT', ' DEI ', 'Diversity', 'Equity', 'Inclusion', 'gender',' GBV', 'trans-gender', 'trans-women', 'trans-men', 'disparity', 'pregnant people',\n",
    "            'Gender', 'DEI', 'Diversity', 'Inclusion', 'disparity', 'equity', 'identity', 'inclusivity', 'binary', 'non-binary', 'prejudice',\n",
    "            'pronouns', 'race', 'stereotype', 'tgw', 'transgender', 'tg', 'transgender women', 'trans', 'transgender', 'protecting women', 'key pops', 'key populations', \n",
    "            'MAT', 'hormone', 'gbv', 'dreams', 'abortion', 'fsw', 'female sex worker', 'food']  # Add more keywords as needed\n",
    "# Generate and save report\n",
    "df = generate_report(folder_path, keywords)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb02cb0a945b46e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:39:01.265451Z",
     "start_time": "2025-02-13T14:39:01.240022Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(f\"{folder_path}_keyword_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a68d75655f5f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:39:04.510868Z",
     "start_time": "2025-02-13T14:39:04.479613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['File Path', 'Source Type', 'Source Name', 'Location', 'Keyword',\n",
      "       'Exact Sentence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d7dfbd33ee2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:39:07.334605Z",
     "start_time": "2025-02-13T14:39:07.316253Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'File Path': 'Path', \n",
    "                   'Exact Sentence': 'Content'}, inplace=True\n",
    "          )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ff5bccecd6f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:39:09.063721Z",
     "start_time": "2025-02-13T14:39:09.041424Z"
    }
   },
   "outputs": [],
   "source": [
    "df_copy = df.assign(\n",
    "    Partner = df['Path'].str.extract(r'\\\\(.*?)\\.(xlsx|pdf)')[0]\n",
    ")[['Partner', 'Keyword', 'Content']]\n",
    "\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1cd44d33681f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:39:10.296267Z",
     "start_time": "2025-02-13T14:39:10.280602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Validation passed: All extracted filenames are correct!\n"
     ]
    }
   ],
   "source": [
    "# Validation Tests (Win + .)\n",
    "assert df_copy['Partner'].isnull().sum() == 0, \"âŒ Missing values found in 'Partner' column\"\n",
    "assert all(df_copy['Partner'].str.contains(r'[^\\\\/]+', regex=True)), \"ðŸ¤£ 'Partner' column contains invalid values\"\n",
    "\n",
    "print(\"âœ… Validation passed: All extracted filenames are correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01d86a1670ceda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:39:12.512812Z",
     "start_time": "2025-02-13T14:39:12.450402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to excel\n",
    "df_copy.to_excel(f\"{folder_path} Keywords Check.xlsx\", \n",
    "                 index=True,\n",
    "                 index_label='No.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eo-compliance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
